---
id: 0004
title: AI Chatbot Technical Research
stage: misc
date: 2025-12-14
surface: agent
model: claude-sonnet-4-5-20250929
feature: ai-chatbot
branch: 004-ai-chatbot
user: system
command: /sp.clarify
labels: [research, technical-decisions, architecture, phase3, chatbot]
links:
  spec: specs/004-ai-chatbot/spec.md
  ticket: null
  adr: null
  pr: null
files:
  - path: specs/004-ai-chatbot/research.md
    status: created
    lines: 550
tests: []
---

## Prompt

**IMPORTANT: Before creating research, you MUST:**
1. Read `.specify/memory/constitution.md` to understand Phase 3 requirements
2. Read `specs/004-ai-chatbot/spec.md` to understand feature requirements
3. Read `specs/004-ai-chatbot/plan.md` to understand technical decisions

Create research document for **Phase 3: AI-Powered Todo Chatbot** in `specs/004-ai-chatbot/research.md`.

**Format:**
- Feature: 004-ai-chatbot
- Date: [current date]
- Status: Complete

**Research Topics Required (7 topics):**

**1. OpenAI Agents SDK Integration**
- Decision: Use OpenAI Agents SDK with function_tool decorator
- Rationale: Official SDK, structured tool calling, SSE streaming support, model factory pattern
- Alternatives Considered: Direct OpenAI API calls, LangChain, Custom agent loop
- Implementation Pattern: Code example with Agent, Runner, function_tool decorator

**2. MCP Tools Design**
- Decision: In-process MCP tools using function_tool pattern (not subprocess)
- Rationale: Lower latency, shared database session, simpler deployment, easier debugging
- Alternatives Considered: stdio subprocess MCP, HTTP MCP server
- Tool Specifications: Table with all 5 tools showing Parameters, Returns, Service Method

**3. Streaming Architecture**
- Decision: Server-Sent Events (SSE) for streaming responses
- Rationale: Native browser support, one-way server-to-client, FastAPI StreamingResponse support, ChatKit expects streaming
- Alternatives Considered: WebSockets, Long polling, HTTP/2 server push
- Implementation Pattern: Code example with FastAPI StreamingResponse and Runner.run_streamed()

**4. Conversation Persistence**
- Decision: Database-first stateless architecture
- Rationale: Stateless server requirement, horizontal scaling, survives server restarts, clean separation
- Alternatives Considered: In-memory with Redis cache, File-based storage, Session storage
- Flow: Step-by-step stateless request cycle (9 steps)

**5. Model Factory Pattern**
- Decision: Centralized factory with environment-based provider selection
- Rationale: Single configuration point, easy provider switching (OpenAI â†” Gemini), no hardcoded keys, testable
- Implementation Pattern: Code example with OpenAI/Gemini support via environment variables

**6. ChatKit Frontend Integration**
- Decision: Custom backend mode with JWT authentication
- Rationale: Full control over agent logic, Better Auth integration, no Agent Builder dependency
- Implementation Pattern: Code example with custom fetch and JWT token from Better Auth session

**7. Service Layer Design**
- Decision: Extract CRUD logic into service layer with async session management
- Rationale: Shared by MCP tools and REST endpoints, single source of truth, testable, clear dependency injection
- Implementation Pattern: Code example with async session and service methods

**Research Summary Table:**
- Topic | Decision | Confidence
- All 7 topics with High confidence

**Status:** Complete - Ready for Phase 1: Design & Contracts

## Response snapshot

Created comprehensive technical research document for Phase 3 AI-Powered Todo Chatbot covering all 7 key architectural and technical decisions with detailed rationale, alternatives analysis, and implementation patterns.

**Research Document Structure:**
- **Feature**: 004-ai-chatbot
- **File**: specs/004-ai-chatbot/research.md (550 lines)
- **Status**: Complete
- **Topics Covered**: 7

**Research Topics (All High Confidence):**

**1. OpenAI Agents SDK Integration**
- Decision: Use official OpenAI Agents SDK with `function_tool` decorator
- Rationale: Official support, structured tool calling, SSE streaming, model factory pattern
- Alternatives Rejected: Direct API calls (too much boilerplate), LangChain (overkill), Custom loop (reinventing wheel)
- Implementation: Complete code example with Agent, Runner, function_tool pattern

**2. MCP Tools Design**
- Decision: In-process MCP tools (not subprocess-based)
- Rationale: Lower latency (<1ms vs 30-50ms), shared DB session, simpler deployment, easier debugging
- Alternatives Rejected: stdio subprocess MCP (latency), HTTP MCP (overkill)
- Tool Specifications: Complete table with all 5 tools (add/list/complete/delete/update_task)

**3. Streaming Architecture**
- Decision: Server-Sent Events (SSE) for response streaming
- Rationale: Native browser support, one-way perfect for AI, FastAPI first-class support, ChatKit expects SSE
- Alternatives Rejected: WebSockets (bidirectional overkill), Long polling (high latency), HTTP/2 push (deprecated)
- Implementation: Complete FastAPI StreamingResponse example with SSE protocol

**4. Conversation Persistence**
- Decision: Database-first stateless architecture
- Rationale: Constitution Principle XII mandate, horizontal scaling, survives restarts, clean separation
- Alternatives Rejected: In-memory+Redis (violates stateless), File storage (slow), Session storage (not persistent)
- Flow: 9-step stateless request cycle documented with database schema

**5. Model Factory Pattern**
- Decision: Centralized factory with environment-based AI provider selection
- Rationale: Single config point, easy switching (OpenAI â†” Gemini), no hardcoded keys, testable
- Implementation: Complete factory code with OpenAI and Gemini support via env vars

**6. ChatKit Frontend Integration**
- Decision: Custom backend mode with JWT authentication from Better Auth
- Rationale: Full agent control, Better Auth integration, no Agent Builder dependency, user isolation
- Implementation: Complete ChatKit component code with customFetch and JWT injection

**7. Service Layer Design**
- Decision: Extract CRUD logic into async service layer shared by MCP tools and REST
- Rationale: Single source of truth, testable, clear dependency injection, async support, separation of concerns
- Implementation: Complete service layer code examples with usage in both MCP tools and REST endpoints

**Research Summary Table:**
All 7 topics documented with High confidence based on:
- Constitution alignment (especially Principle XII)
- Official documentation support
- Proven patterns from similar projects
- Thorough alternatives evaluation
- Clear implementation paths

**Next Steps**: Proceed with Phase 1: Design & Contracts (database models, schemas)

## Outcome

- âœ… Impact: Comprehensive technical research document created capturing all architectural decisions, rationale, alternatives analysis, and implementation patterns for Phase 3. Ready to guide implementation.
- ðŸ§ª Tests: No automated tests (research document). All 7 topics validated against constitution principles and technical best practices.
- ðŸ“ Files: 1 file created (research.md: 550 lines)
- ðŸ” Next prompts: Begin implementation following research patterns, or `/sp.implement` to execute tasks automatically
- ðŸ§  Reflection: Research successfully documents all critical technical decisions with high confidence. Implementation patterns provide clear guidance. All decisions align with constitution (especially stateless Principle XII). Alternatives thoroughly evaluated with rejection criteria. Code examples ready for implementation.

## Evaluation notes (flywheel)

- Failure modes observed: None. Research document created on first attempt with comprehensive coverage.
- Graders run and results (PASS/FAIL): Manual validation - PASS (all 7 topics documented with rationale, alternatives, implementation patterns)
- Prompt variant (if applicable): Custom `/sp.clarify` workflow adapted for research document creation
- Next experiment (smallest change to try): N/A - ready to proceed with implementation using research patterns

