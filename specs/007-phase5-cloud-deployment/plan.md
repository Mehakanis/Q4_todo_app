# Implementation Plan: Phase V - Advanced Cloud Deployment

**Branch**: `007-phase5-cloud-deployment` | **Date**: 2025-12-29 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `specs/007-phase5-cloud-deployment/spec.md`

**Note**: This plan is generated by the `/sp.plan` command following two comprehensive clarification sessions (PHR-0002, PHR-0003) that resolved 10 critical architectural decisions.

## Summary

Phase V extends the Todo Chatbot application with advanced features (recurring tasks, reminders), event-driven architecture using Apache Kafka, Dapr integration for infrastructure abstraction, and production-ready cloud deployment to Oracle Kubernetes Engine (OKE) with AKS/GKE as secondary targets.

**Primary Requirements**:
- Recurring tasks with RRULE pattern support (daily, weekly, monthly, yearly, custom patterns)
- Due dates with automatic reminders scheduled via Dapr Jobs API
- Event-driven architecture with Kafka for task operations (create, update, complete, delete)
- Microservices: Recurring Task Service, Notification Service
- Local deployment to Minikube with Kafka and Dapr
- Cloud deployment to OKE (always-free tier), AKS, or GKE with CI/CD pipeline
- Monitoring and observability with Prometheus, Grafana, Zipkin

**Technical Approach**:
- **Dapr Integration**: All 5 building blocks (Pub/Sub, State Store, Jobs API, Secrets, Service Invocation) for infrastructure abstraction
- **Kafka Messaging**: 3 topics (task-events, reminders, task-updates) with user_id partitioning (12 partitions)
- **UTC-Only Time Handling**: All recurring calculations in UTC, frontend handles timezone conversion
- **User Context Propagation**: Services trust Dapr mTLS, use user_id from events for isolation
- **Branch-Based CI/CD**: mainâ†’production, developâ†’staging, feature branchesâ†’no auto-deploy

## Technical Context

**Language/Version**:
- Backend: Python 3.13+
- Frontend: TypeScript/Node.js 22+
- Infrastructure: Terraform 1.6+, Kubernetes 1.28+, Dapr 1.12+

**Primary Dependencies**:
- **Backend**: FastAPI, SQLModel, python-dateutil (RRULE parsing), Dapr Python SDK
- **Frontend**: Next.js 16, OpenAI ChatKit, Better Auth
- **Infrastructure**: Apache Kafka (Bitnami for Minikube, Redpanda Cloud for production), Dapr, Prometheus, Grafana, Zipkin
- **Cloud**: OKE (primary), AKS/GKE (secondary)

**Storage**:
- Neon PostgreSQL (task data, conversation history via Dapr State Store)
- Apache Kafka (event streaming, 7-day retention local, 30-day retention cloud)

**Testing**:
- pytest (backend unit/integration tests)
- Vitest (frontend component tests)
- Contract tests for event schemas
- End-to-end tests for recurring task creation and reminder delivery

**Target Platform**:
- Local: Minikube (Kubernetes 1.28+)
- Cloud: Oracle Kubernetes Engine (OKE) always-free tier (2 AMD VMs OR 4 Arm Ampere A1 cores), Azure AKS, Google GKE

**Project Type**: Web application (Next.js frontend + FastAPI backend + microservices)

**Performance Goals**:
- Recurring task creation: <500ms p95 latency
- Event processing: <1s end-to-end (Kafka publish â†’ consumer processing â†’ database write)
- Reminder delivery: Â±30s accuracy from scheduled time
- Kafka throughput: 1000 events/sec sustained
- Horizontal scaling: Up to 12 consumer instances per service (matching partition count)

**Constraints**:
- Stateless pod design (no local state, all state in PostgreSQL or Dapr State Store)
- User isolation enforced at all layers (database, Kafka events, microservices)
- No timezone-aware calculations (UTC-only per Clarification #1)
- Dapr State Store ONLY for conversation history, NOT task caching (per Clarification #4)
- OKE always-free tier: 2 AMD VMs (1 OCPU, 1GB RAM each) OR 4 Arm Ampere cores (24GB RAM total)

**Scale/Scope**:
- 1000+ concurrent users
- 10,000+ tasks with recurring patterns
- 3 Kafka topics, 12 partitions each (36 total partitions)
- 5 microservices (Chat API, Task Service, Recurring Task Service, Notification Service, Audit Service)
- 3 deployment environments (local Minikube, staging, production)

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

### Checks Passed âœ…

1. **Simplicity (Principle #1)**:
   - âœ… Event-driven architecture justified for decoupling recurring task generation from main application
   - âœ… Dapr abstraction prevents vendor lock-in and simplifies infrastructure code
   - âœ… Microservices limited to 2 new services (Recurring Task Service, Notification Service) with clear responsibilities

2. **Testability (Principle #2)**:
   - âœ… All event schemas versioned and documented for contract testing
   - âœ… Idempotent event handlers (check for duplicates before processing)
   - âœ… All 24 success criteria from spec are measurable and testable

3. **User Isolation (Principle #3)**:
   - âœ… All Kafka events include user_id in payload (FR-016a)
   - âœ… Consumers enforce user isolation via user_id (FR-016b)
   - âœ… Database queries filtered by user_id
   - âœ… Dapr mTLS for service-to-service authentication (FR-016c)

4. **Performance (Principle #4)**:
   - âœ… Database indexes on next_occurrence and reminder_at for fast queries
   - âœ… Kafka partitioning by user_id for horizontal scaling
   - âœ… Stateless pod design for easy horizontal scaling

5. **Security (Principle #5)**:
   - âœ… Secrets stored in OCI Vault/Azure Key Vault/Google Secret Manager via Dapr
   - âœ… mTLS enabled for all Dapr service-to-service communication
   - âœ… User context propagation (no JWT tokens between internal services)

### No Violations

All constitution principles are satisfied with justified complexity for event-driven architecture and microservices pattern.

## Project Structure

### Documentation (this feature)

```text
specs/007-phase5-cloud-deployment/
â”œâ”€â”€ spec.md              # Feature specification (53+ functional requirements, 24 success criteria, 10 clarifications)
â”œâ”€â”€ plan.md              # This file (/sp.plan command output)
â”œâ”€â”€ research.md          # Phase 0 technical research (Dapr, Kafka, OKE, RRULE, Monitoring, CI/CD)
â”œâ”€â”€ data-model.md        # Phase 1 database schema changes and migration strategy
â”œâ”€â”€ contracts/           # Phase 1 event schemas and Dapr component templates
â”‚   â”œâ”€â”€ event-schemas.yaml       # Task completion, reminder, update event schemas
â”‚   â”œâ”€â”€ pubsub-kafka.yaml        # Dapr Pub/Sub component for Kafka
â”‚   â”œâ”€â”€ statestore-postgresql.yaml   # Dapr State Store component
â”‚   â”œâ”€â”€ secretstore-kubernetes.yaml  # Dapr Secrets component (local)
â”‚   â”œâ”€â”€ secretstore-oci-vault.yaml   # Dapr Secrets component (OKE)
â”‚   â””â”€â”€ jobs-scheduler.yaml      # Dapr Jobs API configuration
â”œâ”€â”€ checklists/          # Validation checklists
â”‚   â””â”€â”€ requirements.md  # Spec quality checklist (PASSED)
â””â”€â”€ tasks.md             # Phase 2 output (/sp.tasks command - NOT created yet)
```

### Source Code (repository root)

```text
# Web application structure (Phase III + Phase V extensions)
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models.py                    # [MODIFIED] Add Phase V fields (recurring_pattern, reminder_at, etc.)
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ task_service.py          # [MODIFIED] Publish Kafka events on task operations
â”‚   â”‚   â”œâ”€â”€ recurring_task_service.py    # [NEW] Consume task.completed events, create next occurrences
â”‚   â”‚   â””â”€â”€ notification_service.py      # [NEW] Consume reminder events, send notifications
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ tasks.py                 # [MODIFIED] Add recurring pattern and reminder fields
â”‚   â”‚   â””â”€â”€ health.py                # [NEW] Kubernetes health checks
â”‚   â”œâ”€â”€ events/
â”‚   â”‚   â”œâ”€â”€ schemas.py               # [NEW] Event schema definitions (TaskCompletedEvent, ReminderEvent)
â”‚   â”‚   â”œâ”€â”€ publisher.py             # [NEW] Dapr Pub/Sub event publisher
â”‚   â”‚   â””â”€â”€ consumers.py             # [NEW] Dapr Pub/Sub event consumers
â”‚   â”œâ”€â”€ integrations/
â”‚   â”‚   â”œâ”€â”€ dapr_client.py           # [NEW] Dapr HTTP client wrapper
â”‚   â”‚   â””â”€â”€ rrule_parser.py          # [NEW] python-dateutil RRULE parsing
â”‚   â””â”€â”€ config.py                    # [MODIFIED] Add Kafka, Dapr configuration
â”œâ”€â”€ migrations/
â”‚   â””â”€â”€ 006_add_phase5_fields.sql    # [NEW] ALTER TABLE tasks ADD COLUMN recurring_pattern, etc.
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ test_recurring_task_service.py   # [NEW] Test next occurrence calculation
â”‚   â”‚   â””â”€â”€ test_rrule_parser.py     # [NEW] Test RRULE parsing logic
â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â”œâ”€â”€ test_kafka_events.py     # [NEW] Test Kafka event publishing/consuming
â”‚   â”‚   â””â”€â”€ test_dapr_pubsub.py      # [NEW] Test Dapr Pub/Sub integration
â”‚   â””â”€â”€ contract/
â”‚       â””â”€â”€ test_event_schemas.py    # [NEW] Validate event schema compliance
â””â”€â”€ Dockerfile                        # [MODIFIED] Add Dapr sidecar configuration

frontend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ RecurringTaskForm.tsx    # [NEW] UI for creating recurring tasks
â”‚   â”‚   â””â”€â”€ ReminderSettings.tsx     # [NEW] UI for setting reminders
â”‚   â””â”€â”€ lib/
â”‚       â””â”€â”€ rrule-utils.ts           # [NEW] RRULE pattern helpers (simplified)
â””â”€â”€ [existing Phase III files]

# Infrastructure
dapr/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ pubsub-kafka.yaml            # [NEW] Kafka Pub/Sub component
â”‚   â”œâ”€â”€ statestore-postgresql.yaml   # [NEW] PostgreSQL State Store component
â”‚   â”œâ”€â”€ secretstore-kubernetes.yaml  # [NEW] Kubernetes Secrets component (Minikube)
â”‚   â”œâ”€â”€ secretstore-oci-vault.yaml   # [NEW] OCI Vault Secrets component (OKE)
â”‚   â””â”€â”€ jobs-scheduler.yaml          # [NEW] Dapr Jobs API configuration
â””â”€â”€ config/
    â””â”€â”€ config.yaml                  # [NEW] Dapr configuration (tracing, metrics)

terraform/
â”œâ”€â”€ oke/
â”‚   â”œâ”€â”€ main.tf                      # [NEW] OKE cluster (always-free tier)
â”‚   â”œâ”€â”€ variables.tf                 # [NEW] OKE variables
â”‚   â””â”€â”€ outputs.tf                   # [NEW] OKE outputs (kubeconfig, cluster endpoint)
â”œâ”€â”€ aks/
â”‚   â””â”€â”€ [similar structure for Azure]
â””â”€â”€ gke/
    â””â”€â”€ [similar structure for Google Cloud]

helm/
â”œâ”€â”€ todo-app/
â”‚   â”œâ”€â”€ Chart.yaml                   # [MODIFIED] Add Phase V services
â”‚   â”œâ”€â”€ values.yaml                  # [MODIFIED] Add Kafka, Dapr configuration
â”‚   â”œâ”€â”€ values-minikube.yaml         # [NEW] Minikube-specific values
â”‚   â”œâ”€â”€ values-oke.yaml              # [NEW] OKE-specific values
â”‚   â””â”€â”€ templates/
â”‚       â”œâ”€â”€ recurring-task-service-deployment.yaml   # [NEW] Recurring Task Service
â”‚       â”œâ”€â”€ notification-service-deployment.yaml     # [NEW] Notification Service
â”‚       â”œâ”€â”€ dapr-components.yaml     # [NEW] Dapr component templates
â”‚       â””â”€â”€ [existing Phase IV deployments]
â””â”€â”€ kafka/
    â”œâ”€â”€ values-minikube.yaml         # [NEW] Bitnami Kafka for Minikube
    â””â”€â”€ values-redpanda.yaml         # [NEW] Redpanda Cloud for production

.github/
â””â”€â”€ workflows/
    â”œâ”€â”€ deploy-staging.yml           # [NEW] Deploy to staging on develop branch merge
    â”œâ”€â”€ deploy-production.yml        # [NEW] Deploy to production on main branch merge
    â””â”€â”€ integration-tests.yml        # [MODIFIED] Add Kafka/Dapr integration tests

monitoring/
â”œâ”€â”€ prometheus/
â”‚   â”œâ”€â”€ prometheus.yaml              # [NEW] Prometheus configuration
â”‚   â””â”€â”€ alerts.yaml                  # [NEW] Alert rules for Phase V services
â”œâ”€â”€ grafana/
â”‚   â”œâ”€â”€ dashboards/
â”‚   â”‚   â”œâ”€â”€ kafka-dashboard.json     # [NEW] Kafka metrics dashboard
â”‚   â”‚   â”œâ”€â”€ dapr-dashboard.json      # [NEW] Dapr metrics dashboard
â”‚   â”‚   â””â”€â”€ recurring-tasks-dashboard.json   # [NEW] Recurring tasks metrics
â”‚   â””â”€â”€ datasources.yaml             # [NEW] Prometheus datasource
â””â”€â”€ zipkin/
    â””â”€â”€ zipkin.yaml                  # [NEW] Zipkin distributed tracing
```

**Structure Decision**: Web application structure (Option 2) with additional infrastructure directories for Dapr components, Terraform, Helm charts, and monitoring configuration. The backend is extended with Phase V services (recurring_task_service.py, notification_service.py) while maintaining the existing Phase III structure.

## Complexity Tracking

> **No violations requiring justification**

All complexity is aligned with constitution principles and user requirements. Event-driven architecture and microservices are justified by the need to decouple recurring task generation and reminder delivery from the main application.

---

## Phase 0: Technical Research

*See [research.md](./research.md) for complete technical research documentation.*

### Research Summary

All technical decisions documented with rationale, alternatives considered, and implementation notes:

1. **Dapr Building Blocks**:
   - **Pub/Sub**: Kafka integration for event streaming
   - **State Store**: PostgreSQL for conversation history ONLY (per Clarification #4)
   - **Jobs API**: Exact-time reminder scheduling (chosen over Cron Bindings)
   - **Secrets**: OCI Vault/Azure Key Vault/Google Secret Manager
   - **Service Invocation**: mTLS for service-to-service authentication

2. **Kafka Configuration**:
   - **Local**: Bitnami Kafka Helm chart for Minikube
   - **Production**: Redpanda Cloud Serverless (free tier) or self-hosted Strimzi
   - **Partitioning**: user_id-based with 12 partitions per topic
   - **Retention**: 7 days local, 30 days cloud (per Clarification #3)

3. **Cloud Platform**:
   - **Primary**: Oracle Kubernetes Engine (OKE) always-free tier (2 AMD VMs OR 4 Arm Ampere A1 cores)
   - **Secondary**: Azure AKS, Google GKE
   - **IaC**: Terraform with oracle-terraform-modules/oke module

4. **RRULE Parsing**:
   - **Library**: python-dateutil (mature, RFC 5545 compliant)
   - **Approach**: Hybrid (simplified patterns + full RRULE fallback)

5. **Monitoring**:
   - **Metrics**: Prometheus + Grafana
   - **Tracing**: Zipkin (chosen over Jaeger for simplicity)
   - **Logging**: OCI Logging/Azure Log Analytics/Google Cloud Logging

6. **CI/CD**:
   - **Platform**: GitHub Actions
   - **Strategy**: Branch-based deployment (mainâ†’production, developâ†’staging per Clarification #5)
   - **Rollback**: Automated rollback on deployment failure

---

## Phase 1: Data Model and Contracts

*See [data-model.md](./data-model.md) for complete database schema documentation.*

### Database Schema Changes

**Migration Strategy**: Add nullable columns to existing `tasks` table (existing tasks will have NULL for Phase V fields).

```sql
-- Migration 006: Add Phase V fields
ALTER TABLE tasks
  ADD COLUMN recurring_pattern VARCHAR(500) NULL,  -- RRULE string or simplified pattern (e.g., "FREQ=DAILY;INTERVAL=1")
  ADD COLUMN recurring_end_date TIMESTAMP NULL,   -- When recurring should stop (NULL = infinite)
  ADD COLUMN next_occurrence TIMESTAMP NULL,      -- When next occurrence should be created (UTC)
  ADD COLUMN reminder_at TIMESTAMP NULL,          -- When reminder notification should be sent (UTC)
  ADD COLUMN reminder_sent BOOLEAN DEFAULT FALSE; -- Track if reminder was sent

-- Indexes for performance
CREATE INDEX idx_tasks_next_occurrence
  ON tasks(next_occurrence)
  WHERE next_occurrence IS NOT NULL;

CREATE INDEX idx_tasks_reminder_at
  ON tasks(reminder_at, user_id)
  WHERE reminder_at IS NOT NULL AND reminder_sent = FALSE;

-- Rollback
ALTER TABLE tasks
  DROP COLUMN recurring_pattern,
  DROP COLUMN recurring_end_date,
  DROP COLUMN next_occurrence,
  DROP COLUMN reminder_at,
  DROP COLUMN reminder_sent;
```

### Event Schemas

*See [contracts/event-schemas.yaml](./contracts/event-schemas.yaml) for complete event schema definitions.*

**All events follow this base structure**:
```json
{
  "event_id": "uuid-v4",           // Unique event identifier for idempotency
  "event_type": "task.completed",  // Event type (task.completed, reminder.scheduled, task.updated)
  "event_version": "1.0",          // Schema version for evolution
  "timestamp": "2025-12-29T12:00:00Z",  // Event creation time (UTC)
  "user_id": "uuid-string",        // User context for isolation (per Clarification #2)
  "task_id": 123,                  // Task identifier
  "payload": { ... }               // Event-specific payload
}
```

**Event Types**:
1. **task.completed**: Published when recurring task is marked complete â†’ triggers next occurrence creation
2. **reminder.scheduled**: Published when task with due_date is created â†’ triggers reminder delivery
3. **task.updated**: Published when task fields are modified â†’ triggers audit logging

### Dapr Components

*See [contracts/](./contracts/) for Dapr component YAML templates.*

**Components**:
1. **pubsub-kafka.yaml**: Kafka Pub/Sub (3 topics: task-events, reminders, task-updates)
2. **statestore-postgresql.yaml**: PostgreSQL State Store (conversation history only)
3. **secretstore-kubernetes.yaml**: Kubernetes Secrets (Minikube)
4. **secretstore-oci-vault.yaml**: OCI Vault Secrets (OKE)
5. **jobs-scheduler.yaml**: Dapr Jobs API (reminder scheduling)

---

## Architecture Overview

### System Context Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Todo Chatbot System                         â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚   ChatKit    â”‚â”€â”€â”€â–¶â”‚   Chat API   â”‚â”€â”€â”€â–¶â”‚ Task Service â”‚         â”‚
â”‚  â”‚   Frontend   â”‚    â”‚  (MCP Tools) â”‚    â”‚  (FastAPI)   â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                              â”‚                    â”‚                 â”‚
â”‚                              â”‚                    â–¼                 â”‚
â”‚                              â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚                              â”‚            â”‚ PostgreSQL   â”‚          â”‚
â”‚                              â”‚            â”‚ (Neon)       â”‚          â”‚
â”‚                              â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                              â”‚                                      â”‚
â”‚                              â–¼                                      â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚                      â”‚    Kafka     â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚                      â”‚ (3 topics)   â”‚                 â”‚            â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚            â”‚
â”‚                             â”‚                         â”‚            â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚            â”‚
â”‚          â”‚                  â”‚                  â”‚      â”‚            â”‚
â”‚          â–¼                  â–¼                  â–¼      â”‚            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚           â”‚
â”‚  â”‚  Recurring   â”‚  â”‚ Notification â”‚  â”‚    Audit     â”‚â”‚           â”‚
â”‚  â”‚Task Service  â”‚  â”‚   Service    â”‚  â”‚   Service    â”‚â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚           â”‚
â”‚         â”‚                  â”‚                           â”‚           â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                            â”‚                                        â”‚
â”‚                            â–¼                                        â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚                    â”‚ Dapr Sidecar â”‚                                â”‚
â”‚                    â”‚ (all pods)   â”‚                                â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                   â”‚                   â”‚
        â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Prometheus  â”‚  â”‚    Zipkin    â”‚  â”‚   Grafana    â”‚
â”‚  (Metrics)   â”‚  â”‚  (Tracing)   â”‚  â”‚ (Dashboards) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Microservices Architecture

**Service Responsibilities**:

1. **Chat API (Existing - Phase III)**:
   - Handle ChatKit conversation
   - Invoke MCP tools (add_task, list_tasks, complete_task, etc.)
   - **[NEW]** Publish Kafka events on task operations
   - Store conversation history in Dapr State Store

2. **Task Service (Existing - Phase II/III)**:
   - CRUD operations on tasks table
   - **[NEW]** Publish task.completed events when task marked complete
   - **[NEW]** Publish reminder.scheduled events when task with due_date created
   - Enforce user isolation (filter by user_id)

3. **Recurring Task Service (NEW - Phase V)**:
   - **Subscribe to**: task.completed events on task-events topic
   - **Responsibility**: Create next occurrence when recurring task completed
   - **Idempotency**: Check if next occurrence already exists before creating
   - **Scaling**: Horizontal scaling up to 12 instances (matching partition count)

4. **Notification Service (NEW - Phase V)**:
   - **Subscribe to**: reminder.scheduled events on reminders topic
   - **Responsibility**: Send email/push notifications at scheduled time
   - **Dapr Integration**: Use Dapr Jobs API for exact-time scheduling
   - **Retry Strategy**: 10 retries with exponential backoff (per Clarification #1 from PHR-0002)

5. **Audit Service (Optional - Phase V)**:
   - **Subscribe to**: task.updated events on task-updates topic
   - **Responsibility**: Log all task modifications for audit trail
   - **Storage**: Separate audit_logs table or external logging service

### Event Flow: Recurring Task Completion

```
1. User marks recurring task complete via ChatKit
   â†“
2. Chat API calls complete_task MCP tool
   â†“
3. Task Service updates task.completed_at in database
   â†“
4. Task Service publishes task.completed event to Kafka (task-events topic)
   â†“
5. Kafka routes event to partition based on user_id hash
   â†“
6. Recurring Task Service consumes event from partition
   â†“
7. Recurring Task Service calculates next_occurrence (UTC, python-dateutil)
   â†“
8. Recurring Task Service creates next task occurrence in database
   â†“
9. Task Service publishes task.created event to Kafka
   â†“
10. Frontend receives updated task list (optional WebSocket notification)
```

### Event Flow: Reminder Scheduling

```
1. User creates task with due_date via ChatKit
   â†“
2. Chat API calls add_task MCP tool with due_date parameter
   â†“
3. Task Service creates task in database with reminder_at = due_date - 1 hour
   â†“
4. Task Service publishes reminder.scheduled event to Kafka (reminders topic)
   â†“
5. Notification Service consumes reminder.scheduled event
   â†“
6. Notification Service schedules reminder using Dapr Jobs API
   â†“
7. At reminder_at time, Dapr Jobs API invokes Notification Service webhook
   â†“
8. Notification Service sends email notification via SMTP
   â†“
9. Notification Service updates task.reminder_sent = TRUE in database
```

---

## Deployment Strategy

### Part B: Local Deployment (Minikube)

**Prerequisites**:
- Minikube 1.32+ (Docker driver)
- kubectl 1.28+
- Helm 3.13+
- Dapr CLI 1.12+

**Deployment Script** (`scripts/deploy-minikube.sh`):

```bash
#!/bin/bash
set -e

echo "ðŸš€ Phase V: Local Deployment to Minikube"

# 1. Start Minikube
echo "ðŸ“¦ Starting Minikube..."
minikube start --cpus=4 --memory=8192 --driver=docker
eval $(minikube docker-env)

# 2. Install Dapr to Minikube
echo "ðŸ”§ Installing Dapr..."
dapr init -k --runtime-version 1.12 --enable-ha=false

# 3. Deploy Kafka using Bitnami Helm chart
echo "ðŸ“¨ Deploying Kafka..."
helm repo add bitnami https://charts.bitnami.com/bitnami
helm install kafka bitnami/kafka \
  --set persistence.size=10Gi \
  --set replicaCount=1 \
  --set listeners.client.protocol=PLAINTEXT \
  --wait

# 4. Create Kafka topics (12 partitions, 7-day retention per Clarification #3)
echo "ðŸ“‹ Creating Kafka topics..."
kubectl run kafka-client --restart='Never' --image docker.io/bitnami/kafka:3.6.0 --rm -it -- \
  kafka-topics.sh --create --topic task-events --partitions 12 --replication-factor 1 \
  --config retention.ms=604800000 --bootstrap-server kafka:9092

kubectl run kafka-client --restart='Never' --image docker.io/bitnami/kafka:3.6.0 --rm -it -- \
  kafka-topics.sh --create --topic reminders --partitions 12 --replication-factor 1 \
  --config retention.ms=604800000 --bootstrap-server kafka:9092

kubectl run kafka-client --restart='Never' --image docker.io/bitnami/kafka:3.6.0 --rm -it -- \
  kafka-topics.sh --create --topic task-updates --partitions 12 --replication-factor 1 \
  --config retention.ms=604800000 --bootstrap-server kafka:9092

# 5. Apply Dapr components
echo "âš™ï¸  Applying Dapr components..."
kubectl apply -f dapr/components/pubsub-kafka.yaml
kubectl apply -f dapr/components/statestore-postgresql.yaml
kubectl apply -f dapr/components/secretstore-kubernetes.yaml
kubectl apply -f dapr/components/jobs-scheduler.yaml

# 6. Deploy application using Helm
echo "ðŸŽ¯ Deploying Todo application..."
helm install todo-app ./helm/todo-app -f ./helm/todo-app/values-minikube.yaml --wait

# 7. Deploy monitoring stack
echo "ðŸ“Š Deploying monitoring..."
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm install prometheus prometheus-community/kube-prometheus-stack \
  --set grafana.adminPassword=admin \
  --wait

kubectl apply -f monitoring/zipkin/zipkin.yaml

# 8. Verify deployment
echo "âœ… Verifying deployment..."
kubectl get pods
kubectl get daprcomponents
dapr dashboard -k

echo "ðŸŽ‰ Deployment complete!"
echo "ðŸ“Š Grafana: http://$(minikube ip):30000 (admin/admin)"
echo "ðŸ” Zipkin: http://$(minikube ip):30001"
echo "ðŸŽ›ï¸  Dapr Dashboard: http://localhost:8080"
```

### Part C: Cloud Deployment (OKE/AKS/GKE)

**Primary Target**: Oracle Kubernetes Engine (OKE) Always-Free Tier

**OKE Always-Free Resources** (per Clarification #1 from PHR-0002):
- **Compute**: 2 AMD VMs (1 OCPU, 1GB RAM each) **OR** 4 Arm Ampere A1 cores (24GB RAM total)
- **Storage**: 200GB total block storage
- **Networking**: Load Balancer (10Mbps)

**Terraform Configuration** (`terraform/oke/main.tf`):

```hcl
terraform {
  required_providers {
    oci = {
      source  = "oracle/oci"
      version = "~> 5.0"
    }
  }
}

provider "oci" {
  region           = var.region
  tenancy_ocid     = var.tenancy_ocid
  user_ocid        = var.user_ocid
  fingerprint      = var.fingerprint
  private_key_path = var.private_key_path
}

module "oke" {
  source  = "oracle-terraform-modules/oke/oci"
  version = "~> 5.0"

  # Cluster Configuration
  compartment_id      = var.compartment_ocid
  cluster_name        = "todo-phase5-production"
  kubernetes_version  = "v1.28.2"

  # VCN Configuration
  create_vcn = true
  vcn_name   = "todo-vcn"

  # Always-Free Tier Node Pool (Arm Ampere A1)
  node_pools = {
    worker_pool = {
      shape              = "VM.Standard.A1.Flex"
      node_pool_size     = 2
      ocpus              = 2        # 2 cores per node (4 total)
      memory_in_gbs      = 12       # 12GB per node (24GB total)
      boot_volume_size   = 50       # 50GB per node (100GB total)

      # Dapr-optimized labels
      node_labels = {
        "dapr.io/enabled" = "true"
        "pool"            = "workers"
      }
    }
  }

  # Bastion host (optional, for debugging)
  create_bastion_host = false

  # Load balancer (always-free tier: 10Mbps)
  load_balancers = "public"
}

# Install Dapr to OKE cluster
resource "null_resource" "install_dapr" {
  depends_on = [module.oke]

  provisioner "local-exec" {
    command = <<-EOT
      kubectl config use-context ${module.oke.cluster_id}
      dapr init -k --runtime-version 1.12 --enable-ha=true --enable-mtls=true
    EOT
  }
}

# Deploy Redpanda Cloud (free tier) for Kafka
# Note: Redpanda Cloud free tier provides 10GB storage, 10MB/s throughput
# Alternative: Use Strimzi Operator to self-host Kafka on OKE (uses more resources)
```

**CI/CD Pipeline** (`.github/workflows/deploy-production.yml`):

```yaml
name: Deploy to Production (OKE)

on:
  push:
    branches:
      - main  # Trigger on merge to main (per Clarification #5)

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build and push Docker images
        uses: docker/build-push-action@v5
        with:
          context: ./backend
          push: true
          tags: ${{ secrets.OCI_REGISTRY }}/todo-backend:${{ github.sha }}

      - name: Install kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'v1.28.0'

      - name: Configure kubectl for OKE
        run: |
          mkdir -p $HOME/.kube
          echo "${{ secrets.OKE_KUBECONFIG }}" | base64 -d > $HOME/.kube/config

      - name: Deploy to OKE using Helm
        run: |
          helm upgrade --install todo-app ./helm/todo-app \
            -f ./helm/todo-app/values-oke.yaml \
            --set image.tag=${{ github.sha }} \
            --wait --timeout 10m

      - name: Run health checks
        run: |
          kubectl rollout status deployment/todo-backend
          kubectl rollout status deployment/recurring-task-service
          kubectl rollout status deployment/notification-service

      - name: Run integration tests
        run: |
          kubectl run integration-tests --image=${{ secrets.OCI_REGISTRY }}/todo-tests:latest \
            --restart=Never --rm -it -- pytest tests/integration/

      - name: Rollback on failure
        if: failure()
        run: |
          helm rollback todo-app --wait
```

---

## Monitoring and Observability

### Metrics (Prometheus + Grafana)

**Key Metrics**:
1. **Kafka Metrics**:
   - `kafka_topic_partition_current_offset` - Message offset per partition
   - `kafka_consumer_lag_seconds` - Consumer lag in seconds
   - `kafka_messages_per_second` - Message throughput

2. **Dapr Metrics**:
   - `dapr_component_pubsub_ingress_count` - Events published
   - `dapr_component_pubsub_egress_count` - Events consumed
   - `dapr_http_server_request_duration_ms` - Service invocation latency

3. **Application Metrics**:
   - `recurring_tasks_created_total` - Counter of next occurrences created
   - `reminders_sent_total` - Counter of reminders sent
   - `next_occurrence_calculation_duration_seconds` - RRULE calculation latency

**Grafana Dashboards**:
- `kafka-dashboard.json` - Kafka topic metrics, consumer lag, partition distribution
- `dapr-dashboard.json` - Dapr component health, service invocation success rate
- `recurring-tasks-dashboard.json` - Recurring task creation rate, next occurrence distribution

### Distributed Tracing (Zipkin)

**Why Zipkin over Jaeger**: Simpler deployment (single binary), lower resource usage, sufficient for Phase V scope (research decision documented in research.md).

**Trace Spans**:
1. **task.completed Event Flow**:
   - Span 1: Task Service publishes event to Kafka
   - Span 2: Kafka brokers event to partition
   - Span 3: Recurring Task Service consumes event
   - Span 4: Recurring Task Service creates next occurrence in database

2. **Reminder Scheduling Flow**:
   - Span 1: Task Service publishes reminder.scheduled event
   - Span 2: Notification Service consumes event
   - Span 3: Notification Service schedules job via Dapr Jobs API
   - Span 4: Notification Service sends email via SMTP

**Configuration**: Dapr automatic instrumentation enabled via `dapr/config/config.yaml`:

```yaml
apiVersion: dapr.io/v1alpha1
kind: Configuration
metadata:
  name: dapr-config
spec:
  tracing:
    samplingRate: "1"  # 100% sampling for Phase V (reduce to 0.1 for production)
    zipkin:
      endpointAddress: "http://zipkin:9411/api/v2/spans"
  metric:
    enabled: true
```

### Logging (OCI Logging / Azure Log Analytics / Google Cloud Logging)

**Log Aggregation**: Centralized logging with structured JSON logs.

**Log Fields**:
- `timestamp` (ISO 8601, UTC)
- `level` (DEBUG, INFO, WARN, ERROR)
- `service` (recurring-task-service, notification-service, etc.)
- `user_id` (for user-level filtering)
- `event_id` (for tracing events across services)
- `message` (human-readable log message)

**Example Log Entry**:
```json
{
  "timestamp": "2025-12-29T12:00:00Z",
  "level": "INFO",
  "service": "recurring-task-service",
  "user_id": "user-123",
  "event_id": "evt-456",
  "message": "Created next occurrence for recurring task",
  "task_id": 789,
  "next_due": "2025-12-30T09:00:00Z"
}
```

---

## Security

### Inter-Service Authentication (per Clarification #2)

**Approach**: User context propagation with Dapr mTLS.

- **No JWT tokens between internal services** (per Clarification #2 from PHR-0003)
- **Services trust Dapr mTLS** for service-to-service authentication
- **Events include user_id** in payload for user-level authorization
- **Consuming services use user_id** for database filtering and user isolation

### Secrets Management

**Dapr Secrets Components**:
- **Minikube**: Kubernetes Secrets (`secretstore-kubernetes.yaml`)
- **OKE**: OCI Vault (`secretstore-oci-vault.yaml`)
- **AKS**: Azure Key Vault
- **GKE**: Google Secret Manager

**Secrets Stored**:
- `DATABASE_URL` (Neon PostgreSQL connection string)
- `KAFKA_BROKERS` (Kafka broker addresses)
- `SMTP_PASSWORD` (Email notification credentials)
- `BETTER_AUTH_SECRET` (Better Auth JWT secret)

### Network Policies

**Kubernetes Network Policies**:
```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: recurring-task-service-policy
spec:
  podSelector:
    matchLabels:
      app: recurring-task-service
  policyTypes:
    - Ingress
    - Egress
  ingress:
    - from:
      - podSelector:
          matchLabels:
            dapr.io/enabled: "true"  # Only allow Dapr sidecar traffic
  egress:
    - to:
      - podSelector:
          matchLabels:
            app: kafka  # Allow Kafka connections
    - to:
      - podSelector:
          matchLabels:
            app: postgres  # Allow database connections
```

---

## Implementation Phases

### Phase 1: Database Migration (1 day)
- [ ] Create migration 006_add_phase5_fields.sql
- [ ] Add indexes on next_occurrence and reminder_at
- [ ] Test migration on local PostgreSQL
- [ ] Test rollback script

### Phase 2: Event Schemas and Dapr Components (2 days)
- [ ] Define event schemas (task.completed, reminder.scheduled, task.updated)
- [ ] Create Dapr Pub/Sub component (pubsub-kafka.yaml)
- [ ] Create Dapr State Store component (statestore-postgresql.yaml)
- [ ] Create Dapr Secrets component (secretstore-kubernetes.yaml)
- [ ] Create Dapr Jobs API component (jobs-scheduler.yaml)
- [ ] Write contract tests for event schemas

### Phase 3: RRULE Parsing and Next Occurrence Calculation (3 days)
- [ ] Implement RRULE parser using python-dateutil
- [ ] Implement next occurrence calculation (UTC-only per Clarification #1)
- [ ] Handle recurring_end_date logic
- [ ] Write unit tests for RRULE parsing (daily, weekly, monthly, yearly, custom)
- [ ] Write unit tests for edge cases (DST transitions, leap years, timezone boundaries)

### Phase 4: Recurring Task Service (3 days)
- [ ] Implement task.completed event consumer
- [ ] Implement next occurrence creation logic with idempotency check
- [ ] Integrate python-dateutil for next_occurrence calculation
- [ ] Publish task.created event for next occurrence
- [ ] Write integration tests with Kafka
- [ ] Write contract tests for event consumption

### Phase 5: Notification Service (3 days)
- [ ] Implement reminder.scheduled event consumer
- [ ] Integrate Dapr Jobs API for exact-time scheduling
- [ ] Implement email notification via SMTP
- [ ] Implement retry strategy (10 retries, exponential backoff)
- [ ] Update task.reminder_sent flag after successful delivery
- [ ] Write integration tests with Dapr Jobs API

### Phase 6: Task Service Updates (2 days)
- [ ] Add recurring_pattern, reminder_at fields to task creation API
- [ ] Publish task.completed event when task marked complete
- [ ] Publish reminder.scheduled event when task with due_date created
- [ ] Update task.reminder_sent flag after notification
- [ ] Write API tests for new fields

### Phase 7: Local Deployment (Minikube) (3 days)
- [ ] Write deploy-minikube.sh script
- [ ] Deploy Kafka using Bitnami Helm chart
- [ ] Create Kafka topics with 12 partitions, 7-day retention
- [ ] Install Dapr to Minikube
- [ ] Apply Dapr components
- [ ] Deploy application using Helm
- [ ] Deploy monitoring stack (Prometheus, Grafana, Zipkin)
- [ ] Test end-to-end recurring task flow on Minikube

### Phase 8: Cloud Deployment (OKE) (5 days)
- [ ] Write Terraform configuration for OKE always-free tier
- [ ] Provision OKE cluster (2 Arm Ampere A1 nodes)
- [ ] Set up Redpanda Cloud free tier for Kafka
- [ ] Install Dapr to OKE with mTLS enabled
- [ ] Apply Dapr components (OCI Vault for secrets)
- [ ] Configure CI/CD pipeline (GitHub Actions)
- [ ] Deploy application to OKE using Helm
- [ ] Configure monitoring (Prometheus, Grafana, Zipkin)
- [ ] Run integration tests on OKE
- [ ] Test automated rollback on deployment failure

**Total Estimated Timeline**: 22 days (4.5 weeks) for single developer

---

## Risk Mitigation

### Risk 1: Kafka Consumer Lag
**Impact**: High - Delayed recurring task creation or reminder delivery

**Mitigation**:
- Monitor `kafka_consumer_lag_seconds` metric
- Alert if lag exceeds 60 seconds
- Horizontal scaling: Add consumer instances (up to 12 per service)
- Increase partition count if needed (requires topic recreation)

### Risk 2: RRULE Calculation Errors
**Impact**: Medium - Incorrect next occurrence dates

**Mitigation**:
- Comprehensive unit tests for all RRULE patterns (daily, weekly, monthly, yearly, custom)
- Edge case testing: DST transitions, leap years, timezone boundaries, recurring_end_date
- Fallback: Log calculation errors to Sentry, continue processing other events
- Manual recovery API for correcting incorrect next occurrences

### Risk 3: Dapr Component Failures
**Impact**: High - Event publishing/consuming breaks, reminders not delivered

**Mitigation**:
- Dapr High Availability (HA) mode enabled on cloud deployments
- Dapr sidecar restarts automatically on crash (Kubernetes liveness probe)
- Circuit breaker: Disable Dapr component if failure rate exceeds 50%
- Fallback: Direct Kafka client for critical operations (requires manual intervention)

### Risk 4: OKE Always-Free Tier Resource Limits
**Impact**: Medium - Insufficient resources for all services

**Mitigation**:
- Resource requests/limits tuned for always-free tier (2 cores, 24GB RAM total)
- Horizontal Pod Autoscaler (HPA) disabled to avoid exceeding free tier
- Vertical scaling: Use Arm Ampere A1 shape (4 cores, 24GB RAM) instead of AMD
- Monitoring: Alert if CPU usage exceeds 80% or memory exceeds 18GB
- Fallback: Migrate to AKS/GKE if OKE free tier insufficient

### Risk 5: Event Schema Evolution Breaking Changes
**Impact**: High - Old consumers can't process new event versions

**Mitigation**:
- Event schema versioning (event_version field in all events)
- Backward compatibility: New fields are optional, old fields never removed
- Consumer version checks: Reject events with unsupported event_version
- Schema registry (optional): Use Confluent Schema Registry for centralized validation

---

## Testing Strategy

### Unit Tests
- RRULE parsing logic (python-dateutil integration)
- Next occurrence calculation (all patterns, edge cases)
- Event schema validation (Pydantic models)
- User isolation logic (user_id filtering)

**Coverage Target**: 80% code coverage

### Integration Tests
- Kafka event publishing/consuming (Dapr Pub/Sub)
- Dapr Jobs API scheduling (reminder delivery)
- Database operations (next occurrence creation, reminder_sent updates)
- End-to-end recurring task flow (task completion â†’ next occurrence creation)

**Test Environment**: Minikube with Kafka, Dapr, PostgreSQL

### Contract Tests
- Event schema compliance (task.completed, reminder.scheduled, task.updated)
- Dapr component contracts (Pub/Sub, State Store, Jobs API)
- API contracts (recurring_pattern, reminder_at fields)

**Tool**: pytest with pact-python or custom JSON Schema validation

### End-to-End Tests
- User creates recurring task via ChatKit â†’ next occurrence created after completion
- User creates task with due_date â†’ reminder sent at scheduled time
- User marks recurring task complete â†’ next occurrence appears in task list

**Test Environment**: Staging (OKE cluster with Redpanda Cloud)

### Load Tests
- Kafka throughput: 1000 events/sec sustained
- Consumer lag: <1s at 1000 events/sec
- Horizontal scaling: 12 consumer instances processing events in parallel

**Tool**: k6 or Locust

---

## Rollback Strategy

### Database Rollback
- Keep migration 006 rollback script in version control
- Test rollback on local PostgreSQL before production migration
- Rollback procedure: `psql -f migrations/006_rollback.sql`

### Application Rollback
- Helm rollback: `helm rollback todo-app --wait`
- Automated rollback on deployment failure (CI/CD pipeline)
- Rollback window: 15 minutes (Helm keeps last 10 revisions)

### Kafka Topic Rollback
- Kafka topics are append-only (no rollback needed)
- Consumer group offset reset: `kafka-consumer-groups.sh --reset-offsets --to-datetime 2025-12-29T12:00:00Z`
- Dead letter queue: Replay failed events from DLQ after fix

### Dapr Component Rollback
- Version control: Keep old Dapr component YAMLs in git
- Rollback procedure: `kubectl apply -f dapr/components/v1/`
- No downtime: Dapr components support hot-reload

---

## Success Criteria Validation

*Mapping all 24 success criteria from spec.md to implementation plan:*

### Part A: Advanced Features

1. **SC-001**: User can create recurring task with pattern â†’ âœ… Implemented in Phase 6 (Task Service Updates)
2. **SC-002**: Next occurrence created automatically â†’ âœ… Implemented in Phase 4 (Recurring Task Service)
3. **SC-003**: Recurring tasks stop after end date â†’ âœ… Implemented in Phase 3 (RRULE logic)
4. **SC-004**: User receives reminder notification â†’ âœ… Implemented in Phase 5 (Notification Service)
5. **SC-005**: Reminder accuracy Â±30s â†’ âœ… Verified in Phase 5 integration tests
6. **SC-006**: All task operations publish events â†’ âœ… Implemented in Phase 6 (Task Service event publishing)

### Part B: Local Deployment

7. **SC-007**: Application deployed to Minikube â†’ âœ… Implemented in Phase 7 (deploy-minikube.sh)
8. **SC-008**: Kafka topics created â†’ âœ… Implemented in Phase 7 (Kafka topic creation)
9. **SC-009**: Dapr components configured â†’ âœ… Implemented in Phase 2 (Dapr components)
10. **SC-010**: Recurring Task Service consumes events â†’ âœ… Implemented in Phase 4
11. **SC-011**: Notification Service sends reminders â†’ âœ… Implemented in Phase 5
12. **SC-012**: Monitoring dashboards available â†’ âœ… Implemented in Phase 7 (Prometheus, Grafana)

### Part C: Cloud Deployment

13. **SC-013**: Application deployed to OKE/AKS/GKE â†’ âœ… Implemented in Phase 8 (Terraform + CI/CD)
14. **SC-014**: Dapr mTLS enabled â†’ âœ… Implemented in Phase 8 (dapr init -k --enable-mtls=true)
15. **SC-015**: CI/CD pipeline deploys on branch merge â†’ âœ… Implemented in Phase 8 (GitHub Actions)
16. **SC-016**: Health checks pass â†’ âœ… Implemented in Phase 8 (kubectl rollout status)
17. **SC-017**: Integration tests pass â†’ âœ… Implemented in Phase 8 (pytest tests/integration/)
18. **SC-018**: Automated rollback on failure â†’ âœ… Implemented in Phase 8 (helm rollback)
19. **SC-019**: Prometheus metrics collected â†’ âœ… Implemented in Phase 8 (Prometheus deployment)
20. **SC-020**: Grafana dashboards display metrics â†’ âœ… Implemented in Phase 8 (Grafana dashboards)
21. **SC-021**: Distributed traces visible in Zipkin â†’ âœ… Implemented in Phase 8 (Zipkin deployment)
22. **SC-022**: Centralized logs available â†’ âœ… Implemented in Phase 8 (OCI Logging / Azure / GCP)
23. **SC-023**: Secrets stored in vault â†’ âœ… Implemented in Phase 8 (OCI Vault / Azure / GCP)
24. **SC-024**: Horizontal scaling supported â†’ âœ… Implemented in Phase 4/5 (Kafka partitioning, stateless design)

**Validation**: All 24 success criteria mapped to implementation phases. No gaps identified.

---

## Appendices

### A. Glossary

- **RRULE**: Recurrence Rule (RFC 5545) - String format for defining recurring events
- **Dapr**: Distributed Application Runtime - Infrastructure abstraction layer
- **OKE**: Oracle Kubernetes Engine - Managed Kubernetes service from Oracle Cloud
- **AKS**: Azure Kubernetes Service - Managed Kubernetes service from Microsoft Azure
- **GKE**: Google Kubernetes Engine - Managed Kubernetes service from Google Cloud
- **Kafka**: Apache Kafka - Distributed event streaming platform
- **mTLS**: Mutual TLS - Two-way TLS authentication between services
- **DLQ**: Dead Letter Queue - Queue for failed messages that can't be processed

### B. References

- [Dapr Documentation](https://docs.dapr.io/)
- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [Oracle Kubernetes Engine (OKE)](https://docs.oracle.com/en-us/iaas/Content/ContEng/home.htm)
- [RFC 5545 (iCalendar Recurrence Rules)](https://datatracker.ietf.org/doc/html/rfc5545)
- [python-dateutil Documentation](https://dateutil.readthedocs.io/)
- [Zipkin Documentation](https://zipkin.io/pages/quickstart)

### C. Related Documents

- [spec.md](./spec.md) - Phase V Feature Specification
- [research.md](./research.md) - Phase 0 Technical Research
- [data-model.md](./data-model.md) - Phase 1 Database Schema
- [contracts/event-schemas.yaml](./contracts/event-schemas.yaml) - Event Schema Definitions
- [PHR-0002](../../history/prompts/007-phase5-cloud-deployment/0002-phase5-spec-clarification-session.spec.prompt.md) - First Clarification Session
- [PHR-0003](../../history/prompts/007-phase5-cloud-deployment/0003-phase5-spec-second-clarification-session.spec.prompt.md) - Second Clarification Session

---

**Plan Status**: âœ… COMPLETE - Ready for `/sp.tasks` phase

**Next Steps**:
1. Create PHR-0004 for planning phase documentation
2. Run `/sp.tasks` to generate actionable task breakdown from this plan
3. Run `/sp.implement` to execute tasks via Claude Code
