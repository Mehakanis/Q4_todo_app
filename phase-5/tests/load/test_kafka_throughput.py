"""
Load Test: Kafka Throughput

Tests Kafka event throughput under load:
- Verify 1000 events/sec sustained throughput
- Measure event publishing latency
- Verify consumer lag remains low

Uses Locust for load generation.
"""

from locust import HttpUser, task, between, events
import time
from datetime import datetime, timezone
import random


# Configuration
TARGET_EVENTS_PER_SECOND = 1000
TEST_DURATION_SECONDS = 60


class KafkaEventPublisher(HttpUser):
    """
    Locust user that publishes events to Kafka via Backend API.

    Simulates task operations that trigger Kafka events:
    - Task creation → task.created event
    - Task completion → task.completed event
    - Task update → task.updated event
    """
    host = "http://localhost:8000"
    wait_time = between(0.001, 0.01)  # Very short wait for high throughput

    def on_start(self):
        """Sign in and get JWT token."""
        response = self.client.post(
            "/api/auth/signin",
            json={
                "email": "load-test@example.com",
                "password": "load-test-password"
            }
        )

        if response.status_code == 200:
            self.token = response.json()["token"]
            self.user_id = response.json()["user_id"]
        else:
            # Sign up if user doesn't exist
            self.client.post(
                "/api/auth/signup",
                json={
                    "email": "load-test@example.com",
                    "password": "load-test-password",
                    "name": "Load Test User"
                }
            )

            response = self.client.post(
                "/api/auth/signin",
                json={
                    "email": "load-test@example.com",
                    "password": "load-test-password"
                }
            )

            self.token = response.json()["token"]
            self.user_id = response.json()["user_id"]

        self.task_ids = []

    @task(60)
    def create_task(self):
        """
        Create task (publishes task.created event).

        This is the most common operation (60% of load).
        """
        start_time = time.time()

        response = self.client.post(
            f"/api/{self.user_id}/tasks",
            headers={"Authorization": f"Bearer {self.token}"},
            json={
                "title": f"Load Test Task {random.randint(1000, 9999)}",
                "description": "Generated by load test",
                "recurring_pattern": random.choice(["DAILY", "WEEKLY", None])
            },
            name="POST /api/:user_id/tasks (create)"
        )

        if response.status_code == 201:
            task_id = response.json()["id"]
            self.task_ids.append(task_id)

            # Track event publishing latency
            latency_ms = (time.time() - start_time) * 1000
            events.request.fire(
                request_type="EVENT",
                name="task.created",
                response_time=latency_ms,
                response_length=0,
                exception=None,
                context={}
            )

    @task(30)
    def complete_task(self):
        """
        Complete task (publishes task.completed event).

        This triggers next occurrence creation for recurring tasks.
        """
        if not self.task_ids:
            return

        task_id = random.choice(self.task_ids)
        start_time = time.time()

        response = self.client.patch(
            f"/api/{self.user_id}/tasks/{task_id}",
            headers={"Authorization": f"Bearer {self.token}"},
            json={"completed": True},
            name="PATCH /api/:user_id/tasks/:task_id (complete)"
        )

        if response.status_code == 200:
            # Track event publishing latency
            latency_ms = (time.time() - start_time) * 1000
            events.request.fire(
                request_type="EVENT",
                name="task.completed",
                response_time=latency_ms,
                response_length=0,
                exception=None,
                context={}
            )

            # Remove from list
            self.task_ids.remove(task_id)

    @task(10)
    def update_task(self):
        """
        Update task (publishes task.updated event).

        Less common operation (10% of load).
        """
        if not self.task_ids:
            return

        task_id = random.choice(self.task_ids)
        start_time = time.time()

        response = self.client.patch(
            f"/api/{self.user_id}/tasks/{task_id}",
            headers={"Authorization": f"Bearer {self.token}"},
            json={"title": f"Updated Task {random.randint(1000, 9999)}"},
            name="PATCH /api/:user_id/tasks/:task_id (update)"
        )

        if response.status_code == 200:
            # Track event publishing latency
            latency_ms = (time.time() - start_time) * 1000
            events.request.fire(
                request_type="EVENT",
                name="task.updated",
                response_time=latency_ms,
                response_length=0,
                exception=None,
                context={}
            )


@events.test_start.add_listener
def on_test_start(environment, **kwargs):
    """Print test configuration when load test starts."""
    print("=" * 60)
    print("Kafka Throughput Load Test")
    print("=" * 60)
    print(f"Target: {TARGET_EVENTS_PER_SECOND} events/sec")
    print(f"Duration: {TEST_DURATION_SECONDS} seconds")
    print(f"Expected total events: {TARGET_EVENTS_PER_SECOND * TEST_DURATION_SECONDS}")
    print("=" * 60)


@events.test_stop.add_listener
def on_test_stop(environment, **kwargs):
    """Print summary statistics when load test ends."""
    stats = environment.stats

    print("\n" + "=" * 60)
    print("Load Test Results")
    print("=" * 60)

    # Calculate throughput
    total_requests = stats.total.num_requests
    test_runtime = stats.total.last_request_timestamp - stats.total.start_time

    if test_runtime > 0:
        throughput = total_requests / test_runtime
        print(f"Total Requests: {total_requests}")
        print(f"Test Runtime: {test_runtime:.2f}s")
        print(f"Throughput: {throughput:.2f} req/sec")

        # Verify target met
        if throughput >= TARGET_EVENTS_PER_SECOND:
            print(f"✅ Target throughput ACHIEVED: {throughput:.2f} >= {TARGET_EVENTS_PER_SECOND}")
        else:
            print(f"❌ Target throughput MISSED: {throughput:.2f} < {TARGET_EVENTS_PER_SECOND}")

        # Print latency stats
        print(f"\nLatency Statistics:")
        print(f"  Average: {stats.total.avg_response_time:.2f}ms")
        print(f"  Median: {stats.total.median_response_time:.2f}ms")
        print(f"  95th percentile: {stats.total.get_response_time_percentile(0.95):.2f}ms")
        print(f"  99th percentile: {stats.total.get_response_time_percentile(0.99):.2f}ms")
        print(f"  Max: {stats.total.max_response_time:.2f}ms")

        # Print failure rate
        failure_rate = (stats.total.num_failures / total_requests * 100) if total_requests > 0 else 0
        print(f"\nFailure Rate: {failure_rate:.2f}%")

        if failure_rate > 5:
            print("❌ High failure rate detected")
        elif failure_rate > 1:
            print("⚠️  Elevated failure rate")
        else:
            print("✅ Failure rate acceptable")

    print("=" * 60)


# Run with:
# locust -f test_kafka_throughput.py --headless -u 100 -r 10 -t 60s
#
# Parameters:
#   -u 100: 100 concurrent users
#   -r 10: Spawn 10 users per second
#   -t 60s: Run for 60 seconds
