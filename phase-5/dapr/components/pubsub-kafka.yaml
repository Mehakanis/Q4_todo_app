apiVersion: dapr.io/v1alpha1
kind: Component
metadata:
  name: kafka-pubsub
  namespace: default
spec:
  type: pubsub.kafka
  version: v1
  metadata:
    # Kafka broker configuration
    - name: brokers
      value: "kafka:9092"  # Minikube: kafka service, Cloud: update with broker URLs
    - name: consumerGroup
      value: "phase5-consumer-group"
    - name: clientId
      value: "phase5-client"
    - name: authType
      value: "none"  # Minikube: no auth, Cloud: use "sasl_plaintext" or "sasl_ssl"
    # Cloud authentication (uncomment for production)
    # - name: saslUsername
    #   secretKeyRef:
    #     name: kafka-credentials
    #     key: username
    # - name: saslPassword
    #   secretKeyRef:
    #     name: kafka-credentials
    #     key: password
    # - name: saslMechanism
    #   value: "PLAIN"

    # Topic configuration (topics created manually via create-kafka-topics.sh)
    # Topics: task-events, reminders, task-updates
    # Partitions: 12 per topic (for user_id partitioning)
    # Retention: 7 days (Minikube), 30 days (Cloud)

    # Consumer configuration
    - name: maxMessageBytes
      value: "1048576"  # 1MB max message size
    - name: consumeRetryInterval
      value: "200ms"  # Retry interval for failed messages

    # Producer configuration
    - name: enableIdempotence
      value: "true"  # Enable idempotent producer (exactly-once delivery)
    - name: acks
      value: "all"  # Wait for all replicas to acknowledge
    - name: compressionType
      value: "snappy"  # Enable compression for network efficiency

    # Partitioning strategy
    - name: partitionScheme
      value: "hash"  # Hash-based partitioning
    # Note: user_id will be included in event payload for partitioning
    # Kafka will hash user_id to determine partition (ensures ordering per user)

    # Dead Letter Queue (DLQ) Configuration (T083)
    # Retry and DLQ settings per spec.md FR-020a, FR-020c

    # Max delivery attempts before moving to DLQ
    - name: maxDeliveryAttempts
      value: "10"  # Matches max retries for reminders (highest retry count)

    # DLQ Topic Configuration
    # Note: DLQ topics must be created manually with appropriate retention
    # Topics: dlq-task-events, dlq-reminders, dlq-task-updates

    # DLQ retention periods (milliseconds):
    # - dlq-task-events: 30 days = 2,592,000,000 ms
    # - dlq-reminders: 7 days = 604,800,000 ms
    # - dlq-task-updates: 14 days = 1,209,600,000 ms

    # Enable DLQ for this component
    - name: deadLetterTopic
      value: "dlq-{topic}"  # DLQ topic naming pattern: dlq-task-events, dlq-reminders, etc.

    # DLQ Retention Configuration
    # These settings apply when creating DLQ topics via create-kafka-topics.sh
    # Topic retention.ms values:
    # - dlq-task-events: 2592000000 (30 days)
    # - dlq-reminders: 604800000 (7 days)
    # - dlq-task-updates: 1209600000 (14 days)

scopes:
  - backend
  - recurring-task-service
  - notification-service
  - audit-service
